{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-25 18:08:55 WARNING: Can not find mwt: default from official model list. Ignoring it.\n",
      "2022-03-25 18:08:55 INFO: Loading these models for language: en (English):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | combined |\n",
      "| pos       | combined |\n",
      "========================\n",
      "\n",
      "2022-03-25 18:08:55 INFO: Use device: cpu\n",
      "2022-03-25 18:08:55 INFO: Loading: tokenize\n",
      "2022-03-25 18:08:55 INFO: Loading: pos\n",
      "2022-03-25 18:08:56 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import stanza\n",
    "import nltk\n",
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,mwt,pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"datos_features.xlsx\")\n",
    "#df.offense_rating.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>is_humor</th>\n",
       "      <th>humor_rating</th>\n",
       "      <th>humor_controversy</th>\n",
       "      <th>offense_rating</th>\n",
       "      <th>texto_limpio</th>\n",
       "      <th>sentimiento_stanza</th>\n",
       "      <th>...</th>\n",
       "      <th>Religion</th>\n",
       "      <th>Style_of_life</th>\n",
       "      <th>Non_normative</th>\n",
       "      <th>punctuation_symbols_stanza_tagger</th>\n",
       "      <th>primera_plural_stanza</th>\n",
       "      <th>segunda_plural_stanza</th>\n",
       "      <th>tercera_plural_stanza</th>\n",
       "      <th>primera_singular_stanza</th>\n",
       "      <th>segunda_singular_stanza</th>\n",
       "      <th>tercera_singular_stanza</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>TENNESSEE: We're the best state. Nobody even c...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>tennessee we be the good state nobody even com...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>A man inserted an advertisement in the classif...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>a man insert a advertisement in the classified...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>How many men does it take to open a can of bee...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>how many man do it take to open a can of beer ...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Told my mom I hit 1200 Twitter followers. She ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tell my mom i hit twitter follower she point o...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Roses are dead. Love is fake. Weddings are bas...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>rose be dead love be fake wedding be basically...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  id  \\\n",
       "0           0             0   1   \n",
       "1           1             1   2   \n",
       "2           2             2   3   \n",
       "3           3             3   4   \n",
       "4           4             4   5   \n",
       "\n",
       "                                                text  is_humor  humor_rating  \\\n",
       "0  TENNESSEE: We're the best state. Nobody even c...         1          2.42   \n",
       "1  A man inserted an advertisement in the classif...         1          2.50   \n",
       "2  How many men does it take to open a can of bee...         1          1.95   \n",
       "3  Told my mom I hit 1200 Twitter followers. She ...         1          2.11   \n",
       "4  Roses are dead. Love is fake. Weddings are bas...         1          2.78   \n",
       "\n",
       "   humor_controversy  offense_rating  \\\n",
       "0                1.0             0.2   \n",
       "1                1.0             1.1   \n",
       "2                0.0             2.4   \n",
       "3                1.0             0.0   \n",
       "4                0.0             0.1   \n",
       "\n",
       "                                        texto_limpio  sentimiento_stanza  ...  \\\n",
       "0  tennessee we be the good state nobody even com...                   0  ...   \n",
       "1  a man insert a advertisement in the classified...                   1  ...   \n",
       "2  how many man do it take to open a can of beer ...                   0  ...   \n",
       "3  tell my mom i hit twitter follower she point o...                   1  ...   \n",
       "4  rose be dead love be fake wedding be basically...                   1  ...   \n",
       "\n",
       "   Religion  Style_of_life Non_normative punctuation_symbols_stanza_tagger  \\\n",
       "0         0              0             0                                 4   \n",
       "1         0              0             0                                 4   \n",
       "2         0              0             0                                 2   \n",
       "3         0              0             0                                 2   \n",
       "4         0              0             0                                 1   \n",
       "\n",
       "  primera_plural_stanza  segunda_plural_stanza tercera_plural_stanza  \\\n",
       "0                     1                      0                     0   \n",
       "1                     0                      0                     0   \n",
       "2                     0                      0                     0   \n",
       "3                     0                      0                     0   \n",
       "4                     0                      0                     0   \n",
       "\n",
       "   primera_singular_stanza segunda_singular_stanza  tercera_singular_stanza  \n",
       "0                        0                       0                        0  \n",
       "1                        0                       0                        0  \n",
       "2                        0                       0                        1  \n",
       "3                        2                       0                        0  \n",
       "4                        0                       0                        0  \n",
       "\n",
       "[5 rows x 140 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number distinct of nouns, adjectives, adverbs, pronouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000 8000 8000 8000\n"
     ]
    }
   ],
   "source": [
    "texto = df['texto_limpio']\n",
    "postagging = []\n",
    "\n",
    "for i,row in enumerate(texto):\n",
    "    words = row.split()\n",
    "    postagging.append(nltk.pos_tag(words))\n",
    "\n",
    "noun = []\n",
    "adv = []\n",
    "pron = []\n",
    "adj = []\n",
    "\n",
    "\n",
    "freq_noun = []\n",
    "freq_pron = []\n",
    "freq_advs = []\n",
    "freq_adjs = []\n",
    "\n",
    "for i, row in enumerate(postagging):\n",
    "  #  print('oracion',i)\n",
    "\n",
    "    nouns = set()\n",
    "    advs = set()\n",
    "    prons = set()\n",
    "    adjs = set()\n",
    "\n",
    "\n",
    "    for i, tupla in enumerate(row):\n",
    "        \n",
    "        if tupla[1]=='NN' or tupla[1]=='NNS' or tupla[1]=='NNP' or tupla[1]=='NNPS':\n",
    "           # noun.append(tupla[1])\n",
    "            nouns.add(tupla[0])\n",
    "           # print(tupla[0])\n",
    "            \n",
    "        elif tupla[1]=='PRP' or tupla[1]=='PRP$':\n",
    "           # pron.append(tupla[1])\n",
    "            prons.add(tupla[0])\n",
    "          #  print(tupla[0])\n",
    "            \n",
    "        elif tupla[1]=='RB' or tupla[1]=='RBR' or tupla[1]=='RBS':\n",
    "           # adv.append(tupla[1])\n",
    "            advs.add(tupla[0])\n",
    "         #   print(tupla[0])\n",
    "            \n",
    "        elif tupla[1]=='JJ' or tupla[1]=='JJR' or tupla[1]=='JJS':\n",
    "           # adj.append(tupla[1])\n",
    "            adjs.add(tupla[0])\n",
    "          #  print(tupla[0])\n",
    "            \n",
    "    freq_noun.append(len(nouns))\n",
    "    freq_pron.append(len(prons))\n",
    "    freq_advs.append(len(advs))\n",
    "    freq_adjs.append(len(adjs))\n",
    "\n",
    "#print(freq_noun,freq_pron, freq_advs, freq_adjs)       \n",
    "print(len(freq_noun),len(freq_pron), len(freq_advs), len(freq_adjs))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['noun_frequency'] = freq_noun\n",
    "df['pronoun_frequency'] = freq_pron\n",
    "df['adverbs_frequency'] = freq_advs\n",
    "df['adjective_frequency'] = freq_adjs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punctuation with Stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def punctuation(text):\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    puntuacion=set()\n",
    "    for sent in doc.sentences: \n",
    "        for word in sent.words:\n",
    "            if word.upos == 'PUNCT':\n",
    "               # print((word.text,word.upos))\n",
    "                puntuacion.add(word.text)\n",
    "    return len(puntuacion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ejemplo=df['text']\n",
    "lista_puntuacion = []\n",
    "for i in ejemplo:\n",
    "    #print(i)\n",
    "    p = punctuation(i)\n",
    "    lista_puntuacion.append(p)\n",
    "len(lista_puntuacion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['punctuation_symbols_stanza_tagger'] = lista_puntuacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NÂº pronouns plural with Stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pronoun_pl(text):\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    conjunto={}\n",
    "    for word in doc.sentences[0].words: \n",
    "        l = set()\n",
    "        if word.upos == 'PRON':\n",
    "            if word.feats != None and word.feats.find(\"|\"):\n",
    "                for caracteristicas in word.feats.split('|'):\n",
    "                    l.add(caracteristicas)    \n",
    "                    conjunto[word.text] = l\n",
    "\n",
    "    # 1ra, 2da y 3ra persona plural\n",
    "\n",
    "    nprimera_plural=0\n",
    "    nsegunda_plural=0\n",
    "    ntercera_plural=0\n",
    "\n",
    "    for k,v in conjunto.items(): \n",
    "        #print(k) para cada pronoun\n",
    "        for pal in v:\n",
    "            if pal=='Person=1' and  'Number=Plur' in v:\n",
    "                nprimera_plural += 1\n",
    "              #  print('Primera persona plural')\n",
    "\n",
    "            elif pal=='Person=2' and 'Number=Plur' in v:\n",
    "                nsegunda_plural += 1\n",
    "               # print('Segunda persona plural')\n",
    "\n",
    "            elif pal=='Person=3' and 'Number=Plur' in v:\n",
    "                ntercera_plural += 1\n",
    "                #print('Tercera persona plural')\n",
    "    return nprimera_plural,nsegunda_plural,ntercera_plural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "primera_plural=[]\n",
    "segunda_plural=[]\n",
    "tercera_plural=[]\n",
    "\n",
    "for i in df['text']:\n",
    "    p = pronoun_pl(i)\n",
    "    primera_plural.append(p[0])\n",
    "    segunda_plural.append(p[1])\n",
    "    tercera_plural.append(p[2])\n",
    "    \n",
    "len(primera_plural)\n",
    "#primera_plural,segunda_plural,tercera_plural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['primera_plural_stanza']=primera_plural\n",
    "df['segunda_plural_stanza']=segunda_plural\n",
    "df['tercera_plural_stanza']=tercera_plural"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NÂº pronouns singular with Stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pronoun_sg(text):\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    conjunto={}\n",
    "    for word in doc.sentences[0].words: \n",
    "        l = set()\n",
    "        if word.upos == 'PRON':\n",
    "            if word.feats != None and word.feats.find(\"|\"):\n",
    "                for caracteristicas in word.feats.split('|'):\n",
    "                    l.add(caracteristicas)    \n",
    "                    conjunto[word.text] = l\n",
    "\n",
    "    nprimera_singular=0\n",
    "    nsegunda_singular=0\n",
    "    ntercera_singular=0\n",
    "\n",
    "    for k,v in conjunto.items(): \n",
    "        #print(k) para cada pronoun\n",
    "        for pal in v:\n",
    "            if pal=='Person=1' and  'Number=Sing' in v:\n",
    "                nprimera_singular += 1\n",
    "              #  print('Primera persona plural')\n",
    "\n",
    "            elif pal=='Person=2' and 'Number=Sing' in v:\n",
    "                nsegunda_singular += 1\n",
    "               # print('Segunda persona plural')\n",
    "\n",
    "            elif pal=='Person=3' and 'Number=Sing' in v:\n",
    "                ntercera_singular += 1\n",
    "                #print('Tercera persona plural')\n",
    "    return nprimera_singular,nsegunda_singular,ntercera_singular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "primera_singular=[]\n",
    "segunda_singular=[]\n",
    "tercera_singular=[]\n",
    "\n",
    "for i in df['text']:\n",
    "    p = pronoun_sg(i)\n",
    "    primera_singular.append(p[0])\n",
    "    segunda_singular.append(p[1])\n",
    "    tercera_singular.append(p[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['primera_singular_stanza']=primera_singular\n",
    "df['segunda_singular_stanza']=segunda_singular\n",
    "df['tercera_singular_stanza']=tercera_singular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "df.to_excel('/Users/luciainesmerlo/Desktop/TFG/HaHackaton2020/datos_features.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def singular_person(words,p=1):\n",
    "    \n",
    "    if p == 1:\n",
    "         return any(word in (\"i\", \"me\",\"mine\",\"my\", \"myself\") \n",
    "                   for word in words)\n",
    "    \n",
    "    elif p == 2:\n",
    "        return any(word in (\"you\", \"your\",\"yours\",\"yourselfs\", \"yourself\" )\n",
    "                  for word in words)\n",
    "    \n",
    "    else:\n",
    "        return any(word in (\"he\", \"she\",\"him\",\"his\", \"himself\", \"her\",\"hers\", \"herself\",\"it\",\"its\",\"itself\")\n",
    "                  for word in words)\n",
    "    \n",
    "    \n",
    "def plural_person(words,p=1):\n",
    "    \n",
    "    if p == 1:\n",
    "         return any(word in (\"we\",\"us\", \"our\", \"ours\", \"ourselfes\")\n",
    "                   for word in words)\n",
    "    \n",
    "    elif p == 2:\n",
    "        return any(word in (\"you\", \"your\",\"yours\", \"yourselves\" )\n",
    "                  for word in words)\n",
    "    \n",
    "    else:\n",
    "        return any(word in (\"they\", \"them\",\"thier\",\"theirs\", \"theirselves\")\n",
    "                  for word in words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000 8000 8000 8000 8000 8000\n"
     ]
    }
   ],
   "source": [
    "texto = df['texto_limpio']\n",
    "palabras = []\n",
    "for i,row in enumerate(texto):\n",
    "    words = row.split()\n",
    "    #postagging.append(nltk.pos_tag(words))\n",
    "    palabras.append(words)\n",
    "    \n",
    "first_person_singular = []\n",
    "second_person_singular = []\n",
    "third_person_singular = []\n",
    "\n",
    "first_person_plural = []\n",
    "second_person_plural = []\n",
    "third_person_plural = []\n",
    "\n",
    "\n",
    "\n",
    "for i, pal in enumerate(palabras):\n",
    "  #  print('oracion',i)\n",
    "  #  print(pal)\n",
    "    \n",
    "    fs_singular = 0\n",
    "    sd_singular = 0\n",
    "    td_singular = 0\n",
    "    \n",
    "    fs_plural = 0\n",
    "    sd_plural = 0\n",
    "    td_plural = 0\n",
    "    \n",
    "    if singular_person(pal,1):\n",
    "        \n",
    "        fs_singular += 1\n",
    "        \n",
    "    elif singular_person(pal,2):\n",
    "        \n",
    "        sd_singular += 1\n",
    "        \n",
    "    elif singular_person(pal,3):\n",
    "        \n",
    "        td_singular += 1\n",
    "        \n",
    "    elif plural_person(pal,1):\n",
    "        \n",
    "        fs_plural += 1\n",
    "        \n",
    "    elif plural_person(pal,2):\n",
    "        \n",
    "        sd_plural += 1\n",
    "        \n",
    "    elif plural_person(pal,3):\n",
    "        \n",
    "        td_plural += 1\n",
    "    \n",
    "    first_person_singular.append(fs_singular) \n",
    "    second_person_singular.append(sd_singular)\n",
    "    third_person_singular.append(td_singular)\n",
    "    \n",
    "    first_person_plural.append(fs_plural)\n",
    "    second_person_plural.append(sd_plural)\n",
    "    third_person_plural.append(td_plural)\n",
    "    \n",
    "print(len(first_person_singular),len(second_person_singular),len(third_person_singular),\n",
    "     len(first_person_plural),len(second_person_plural),len(third_person_plural)) \n",
    "\n",
    "df['first_person_singular_pronoun']=first_person_singular\n",
    "df['second_person_singular_pronoun']=second_person_singular\n",
    "df['third_person_singular_pronoun']=third_person_singular\n",
    "\n",
    "df['first_person_plural_pronoun']=first_person_plural\n",
    "df['second_person_plural_pronoun']=second_person_plural\n",
    "df['third_person_plural_pronoun']=third_person_plural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def puntuacion():\n",
    "    \n",
    "    punt = r\"(\\(|\\)|\\?|\\Â¿|\\!|\\Â¡|\\.\\.\\.|\\,|\\'|\\\"|\\.|\\;|\\:|\\%)\"\n",
    "    tres = r\"\\.{2,5}\"\n",
    "    numeros = r'[0-9][0-9,./%-:]+'\n",
    "    fecha = r'(\\d{2}(/|-)\\d{2}((/|-)\\d{2,4})?)'\n",
    "    fecha_pals = r\"([0-9]+ de? [\\w].+ de? [0-9]+)\"\n",
    "    webs = r'([\\w://@]+[\\w]+\\.[\\w|\\w-]+\\.[\\w]+)'\n",
    "    correo = r'([^@\\s]+@[\\w]+\\.[\\w]+\\.[\\w]+)'\n",
    "    user = r'(@\\w+\\-?(\\w+)?)'\n",
    "    hasht = r'(#\\w+\\-?(\\w+)?)'\n",
    "    acronimos = r'([A-Z]{1,}[.]+(?:[A-z]{1,}[.])*)'\n",
    "    pals_apos = r\"(\\b[\\w]+'[\\w]+)\" \n",
    "    pals = r\"(\\b\\w+\\b)\"\n",
    "    emojis = r\"[^\\w\\s]\"\n",
    "\n",
    "\n",
    "    patrones = '|'.join([tres,fecha_pals,user,pals_apos,pals,hasht,fecha,acronimos,numeros,webs,emojis,correo,punt])\n",
    "    patron = re.compile(patrones,re.I|re.U)\n",
    "    return patron\n",
    "\n",
    "import string\n",
    "simbolos = [ '(', '\"', ')','\"' , '(' , ')' ,\"|\" , \"?\" ,  \"Â¿\" , \"!\" ,  \"Â¡\" , \"...\" ,\n",
    "           \",\", \"'\", '.', ';',':','%','#','$','&','}','~','^','_','`','{','[',']','\\\\',\n",
    "            '@','*','-','/','<','>','+','\\ '] #, '\\' \n",
    "simbolos = set(simbolos)\n",
    "\n",
    "texto = df['text']\n",
    "punct = []\n",
    "p = puntuacion()\n",
    "sim = []\n",
    "\n",
    "for i,row in enumerate(texto):\n",
    "    simb = set()\n",
    "   \n",
    "    for i in p.finditer(row):\n",
    "        char = row[i.start():i.end()]\n",
    "        if char in simbolos:\n",
    "            simb.add(char)\n",
    "       \n",
    "    sim.append(len(simb))\n",
    "    \n",
    "len(sim)\n",
    "\n",
    "df['punctuation_symbols'] = sim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
