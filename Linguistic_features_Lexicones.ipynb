{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#import os\n",
    "#import stanza\n",
    "from nltk import pos_tag\n",
    "from nltk import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "#os.path.abspath(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"datos_features.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>is_humor</th>\n",
       "      <th>humor_rating</th>\n",
       "      <th>humor_controversy</th>\n",
       "      <th>offense_rating</th>\n",
       "      <th>texto_limpio</th>\n",
       "      <th>sentimiento_stanza</th>\n",
       "      <th>polaridad_media_sentic</th>\n",
       "      <th>sentiwordnet_score</th>\n",
       "      <th>...</th>\n",
       "      <th>Hurtlex-plants</th>\n",
       "      <th>Hurtlex-animals</th>\n",
       "      <th>Hurtlex-male-genitalia</th>\n",
       "      <th>Hurtlex-female-genitalia</th>\n",
       "      <th>Hurtlex-words-prostitution</th>\n",
       "      <th>Hurtlex-words-homosexuality</th>\n",
       "      <th>Hurtlex-potential-negative-connotations</th>\n",
       "      <th>Hurtlex-derogatory-words</th>\n",
       "      <th>Hurtlex-felonies-crime-immoral-behavior</th>\n",
       "      <th>Hurtlex-word-seven-deadly-sins-of-the-Christian-tradition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>TENNESSEE: We're the best state. Nobody even c...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>tennessee we be the good state nobody even com...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.625</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A man inserted an advertisement in the classif...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>a man insert a advertisement in the classified...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.750</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>How many men does it take to open a can of bee...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>how many man do it take to open a can of beer ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.228</td>\n",
       "      <td>-0.375</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 155 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  is_humor  \\\n",
       "0   1  TENNESSEE: We're the best state. Nobody even c...         1   \n",
       "1   2  A man inserted an advertisement in the classif...         1   \n",
       "2   3  How many men does it take to open a can of bee...         1   \n",
       "\n",
       "   humor_rating  humor_controversy  offense_rating  \\\n",
       "0          2.42                1.0             0.2   \n",
       "1          2.50                1.0             1.1   \n",
       "2          1.95                0.0             2.4   \n",
       "\n",
       "                                        texto_limpio  sentimiento_stanza  \\\n",
       "0  tennessee we be the good state nobody even com...                   0   \n",
       "1  a man insert a advertisement in the classified...                   1   \n",
       "2  how many man do it take to open a can of beer ...                   0   \n",
       "\n",
       "   polaridad_media_sentic  sentiwordnet_score  ... Hurtlex-plants  \\\n",
       "0                   0.112               0.625  ...              0   \n",
       "1                   0.404               0.750  ...              0   \n",
       "2                   0.228              -0.375  ...              0   \n",
       "\n",
       "  Hurtlex-animals Hurtlex-male-genitalia  Hurtlex-female-genitalia  \\\n",
       "0               1                      0                         0   \n",
       "1               0                      0                         0   \n",
       "2               0                      1                         0   \n",
       "\n",
       "  Hurtlex-words-prostitution  Hurtlex-words-homosexuality  \\\n",
       "0                          0                            0   \n",
       "1                          0                            0   \n",
       "2                          0                            0   \n",
       "\n",
       "  Hurtlex-potential-negative-connotations  Hurtlex-derogatory-words  \\\n",
       "0                                       0                         0   \n",
       "1                                       0                         1   \n",
       "2                                       0                         1   \n",
       "\n",
       "  Hurtlex-felonies-crime-immoral-behavior  \\\n",
       "0                                       0   \n",
       "1                                       0   \n",
       "2                                       0   \n",
       "\n",
       "   Hurtlex-word-seven-deadly-sins-of-the-Christian-tradition  \n",
       "0                                                  0          \n",
       "1                                                  0          \n",
       "2                                                  0          \n",
       "\n",
       "[3 rows x 155 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hurtlex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>an</td>\n",
       "      <td>996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>asf</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>asm</td>\n",
       "      <td>426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cds</td>\n",
       "      <td>2204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ddf</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ddp</td>\n",
       "      <td>491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dmc</td>\n",
       "      <td>715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>is</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>om</td>\n",
       "      <td>361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>or</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>pa</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>pr</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ps</td>\n",
       "      <td>371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>qas</td>\n",
       "      <td>518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>rci</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>re</td>\n",
       "      <td>619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>svp</td>\n",
       "      <td>527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category  size\n",
       "0        an   996\n",
       "1       asf   144\n",
       "2       asm   426\n",
       "3       cds  2204\n",
       "4       ddf    63\n",
       "5       ddp   491\n",
       "6       dmc   715\n",
       "7        is   124\n",
       "8        om   361\n",
       "9        or   177\n",
       "10       pa   192\n",
       "11       pr   276\n",
       "12       ps   371\n",
       "13      qas   518\n",
       "14      rci    24\n",
       "15       re   619\n",
       "16      svp   527"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hurtlex = pd.read_csv('https://raw.githubusercontent.com/valeriobasile/hurtlex/master/lexica/EN/1.2/hurtlex_EN.tsv', sep='\\t')\n",
    "#df_anew.to_csv('/Users/luciainesmerlo/Desktop/TFG/HaHackaton2020/datos_anew.csv', sep=',')\n",
    "#df_hurtlex = pd.read_csv('datos_hurtlex.csv', sep='\\t')\n",
    "#df_hurtlex.head()\n",
    "df_hurtlex.groupby(['category'],as_index=False).size()#.reset_index(name='counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_hurtlex = {\n",
    "    row['lemma']: {\n",
    "        'category': str(row['category']),\n",
    "        'stereotype': str(row['stereotype'])\n",
    "    }\n",
    "    \n",
    "    for _, row in df_hurtlex.iterrows()\n",
    "}\n",
    "\n",
    "def generate_N_grams(text,ngram=1):\n",
    "    \n",
    "    words=[word for word in text.split(\" \") ]  \n",
    "          \n",
    "    temp=zip(*[words[i:] for i in range(0,ngram)])\n",
    "    ans={' '.join(ngram):1 for ngram in temp}\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "text = df['texto_limpio']\n",
    "\n",
    "ps=[]\n",
    "rci=[]\n",
    "pa=[]\n",
    "ddf=[]\n",
    "ddp=[]\n",
    "dmc=[]\n",
    "is_=[]\n",
    "or_=[]\n",
    "an=[]\n",
    "asm=[]\n",
    "asf=[]\n",
    "pr=[]\n",
    "om=[]\n",
    "qas=[]\n",
    "cds=[]\n",
    "re=[]\n",
    "svp=[]\n",
    "\n",
    "s=set()\n",
    "for i in text: \n",
    "    \n",
    "    unigrama = generate_N_grams(i,1)\n",
    "    bigrama = generate_N_grams(i,2)\n",
    "    gramas = {**unigrama, **bigrama}\n",
    "    \n",
    "    score_ps = 0\n",
    "    score_rci = 0\n",
    "    score_pa = 0\n",
    "    score_ddf = 0\n",
    "    score_ddp = 0\n",
    "    score_dmc = 0\n",
    "    score_is = 0\n",
    "    score_or = 0\n",
    "    score_an = 0\n",
    "    score_asm = 0\n",
    "    score_asf = 0\n",
    "    score_pr = 0\n",
    "    score_om = 0\n",
    "    score_qas = 0\n",
    "    score_cds = 0\n",
    "    score_re = 0\n",
    "    score_svp = 0\n",
    "    \n",
    "    \n",
    "    for key in gramas:\n",
    "        info_word = words_hurtlex.get(key)\n",
    "        if info_word:\n",
    "            category = info_word.get('category')\n",
    "            \n",
    "            if category == 'ps':\n",
    "                score_ps += 1\n",
    "                \n",
    "            elif category == 'rci':\n",
    "                score_rci += 1\n",
    "            \n",
    "            elif category == 'pa':\n",
    "                score_pa += 1\n",
    "                \n",
    "            elif category == 'ddf':\n",
    "                score_ddf += 1\n",
    "                \n",
    "            elif category == 'ddp':\n",
    "                score_ddp += 1\n",
    "                \n",
    "            elif category == 'dmc':\n",
    "                score_dmc += 1\n",
    "                \n",
    "            elif category == 'is':\n",
    "                score_is += 1\n",
    "                \n",
    "            elif category == 'or':\n",
    "                score_or += 1\n",
    "                s.add(key)\n",
    "                \n",
    "            elif category == 'an':\n",
    "                score_an += 1\n",
    "                \n",
    "            elif category == 'asm':\n",
    "                score_asm += 1\n",
    "                \n",
    "            elif category == 'asf':\n",
    "                score_asf += 1\n",
    "                \n",
    "            elif category == 'pr:':\n",
    "                score_pr += 1\n",
    "                \n",
    "            elif category == 'om:':\n",
    "                score_om += 1\n",
    "                \n",
    "            elif category == 'qas':\n",
    "                score_qas += 1\n",
    "                \n",
    "            elif category == 'cds':\n",
    "                score_cds += 1\n",
    "                \n",
    "            elif category == 're':\n",
    "                score_re += 1\n",
    "            \n",
    "            elif category == 'svp':\n",
    "                score_svp += 1\n",
    "            \n",
    "    ps.append(score_ps)\n",
    "    rci.append(score_rci)\n",
    "    pa.append(score_pa)\n",
    "    ddf.append(score_ddf)\n",
    "    ddp.append(score_ddp)\n",
    "    dmc.append(score_dmc)\n",
    "    is_.append(score_is)\n",
    "    or_.append(score_or)\n",
    "    an.append(score_an)\n",
    "    asm.append(score_asm)\n",
    "    asf.append(score_asf)\n",
    "    pr.append(score_pr)\n",
    "    om.append(score_om)\n",
    "    qas.append(score_qas)\n",
    "    cds.append(score_cds)\n",
    "    re.append(score_re)\n",
    "    svp.append(score_svp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['snatch',\n",
       " 'tomato',\n",
       " 'dome',\n",
       " 'faggot',\n",
       " 'bean',\n",
       " 'slit',\n",
       " 'puss',\n",
       " 'turnip',\n",
       " 'squash',\n",
       " 'melon',\n",
       " 'homo',\n",
       " 'cunt',\n",
       " 'pumpkin',\n",
       " 'potato',\n",
       " 'attic',\n",
       " 'bittersweet',\n",
       " 'gay',\n",
       " 'stupid',\n",
       " 'cucumber',\n",
       " 'fag',\n",
       " 'queer',\n",
       " 'noodle']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Hurtlex-negative-stereotypes-ethnic-slurs'] = ps\n",
    "df['Hurtlex-locations-and-demonyms'] = rci\n",
    "df['Hurtlex-professions-and-occupations'] = pa\n",
    "df['Hurtlex-physical-disabilities-and-diversity'] = ddf\n",
    "df['Hurtlex-cognitive disabilities-and-diversity'] = ddp\n",
    "df['Hurtlex-moral-and-behavioral-defects'] = dmc\n",
    "df['Hurtlex-words-social-economic-disadvantage'] = is_\n",
    "df['Hurtlex-plants'] = or_\n",
    "df['Hurtlex-animals'] = an\n",
    "df['Hurtlex-male-genitalia'] = asm\n",
    "df['Hurtlex-female-genitalia'] = asf\n",
    "df['Hurtlex-words-prostitution'] = pr\n",
    "df['Hurtlex-words-homosexuality'] = om\n",
    "df['Hurtlex-potential-negative-connotations'] = qas\n",
    "df['Hurtlex-derogatory-words'] = cds\n",
    "df['Hurtlex-felonies-crime-immoral-behavior'] = re\n",
    "df['Hurtlex-word-seven-deadly-sins-of-the-Christian-tradition'] = svp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EmoSenticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                        word\n",
       "0                       abc\n",
       "1           access internet\n",
       "2                       ace\n",
       "3                achievable\n",
       "4           acknowledgement\n",
       "..                      ...\n",
       "824                   worse\n",
       "825  write computer program\n",
       "826            write friend\n",
       "827    wrong another person\n",
       "828           yellow orange\n",
       "\n",
       "[829 rows x 1 columns]>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#anger, disgust, fear, joy, sad, surprise\n",
    "col = ['word']\n",
    "df_emosenticnet = pd.read_csv(\"/Users/luciainesmerlo/Desktop/TFG/HaHackaton2020/lexicon/EMOSENTICNET/EmoSN_anger.txt\",names=col)\n",
    "df_emosenticnet.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#anger, disgust, fear, joy, sad, surprise\n",
    "df_emosenticnet['emotion'] = 'surprise'\n",
    "lexicon = {row['word'] : row['emotion'] for _, row in df_emosenticnet.iterrows()} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = df['texto_limpio']\n",
    "\n",
    "def generate_N_grams(text,ngram=1):\n",
    "    \n",
    "    words=[word for word in text.split(\" \") ]  \n",
    "          \n",
    "    temp=zip(*[words[i:] for i in range(0,ngram)])\n",
    "    ans={' '.join(ngram):1 for ngram in temp}\n",
    "    return ans\n",
    "\n",
    "l = []\n",
    "\n",
    "for i in text: \n",
    "    \n",
    "    unigrama = generate_N_grams(i,1)\n",
    "    bigrama = generate_N_grams(i,2)\n",
    "    trigrama = generate_N_grams(i,3)\n",
    "    cuatrigrama = generate_N_grams(i,4)\n",
    "    gramas = {**unigrama, **bigrama,**trigrama,**cuatrigrama}\n",
    "    \n",
    "    score = 0\n",
    "    \n",
    "    for key in gramas:\n",
    "        if key in lexicon:\n",
    "            \n",
    "            score += 1\n",
    "            \n",
    "    l.append(score)   \n",
    "len(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### EmoSenticNet  frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['anger_frequency_EmoSenticNet'] = l\n",
    "df['disgust_frequency_EmoSenticNet'] = l\n",
    "df['fear_frequency_EmoSenticNet'] = l\n",
    "df['joy_frequency_EmoSenticNet'] = l\n",
    "df['sad_frequency_EmoSenticNet'] = l\n",
    "df['surprise_frequency_EmoSenticNet'] = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[Group Therapy in Insane Asylum] Therapist: Let's talk about the desires we have to hurt people. Psycho 1: I want to kill people Psycho 2: I want to eat people Psycho 3: I want to post Game Of Thrones spoilers Psycho 1 and 2: What is wrong with you? That is really messed up.\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['sad_frequency_EmoSenticNet'] == 4]['text'][109]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SentiSense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anger,anticipation,disgust, fear,joy, like,love,sadness,surprise\n",
    "col = ['word']\n",
    "import pandas as pd\n",
    "df_sentisense = pd.read_csv(\"/Users/luciainesmerlo/Desktop/TFG/HaHackaton2020/lexicon/SENTISENSE/sentisense_surprise.txt\",names=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(134, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sentisense.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentisense['emotion'] = 'surprise'\n",
    "lexicon = {row['word'] : row['emotion'] for _, row in df_sentisense.iterrows()} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = df['texto_limpio']\n",
    "\n",
    "def generate_N_grams(text,ngram=1):\n",
    "    \n",
    "    words=[word for word in text.split(\" \") ]  \n",
    "          \n",
    "    temp=zip(*[words[i:] for i in range(0,ngram)])\n",
    "    ans={' '.join(ngram):1 for ngram in temp}\n",
    "    return ans\n",
    "\n",
    "l = []\n",
    "\n",
    "for i in text: \n",
    "    \n",
    "    unigrama = generate_N_grams(i,1)\n",
    "    bigrama = generate_N_grams(i,2)\n",
    "    trigrama = generate_N_grams(i,3)\n",
    "    cuatrigrama = generate_N_grams(i,4)\n",
    "    gramas = {**unigrama, **bigrama,**trigrama,**cuatrigrama}\n",
    "    \n",
    "    score = 0\n",
    "    \n",
    "    for key in gramas:\n",
    "        if key in lexicon:\n",
    "            \n",
    "            score += 1\n",
    "            \n",
    "    l.append(score)   \n",
    "len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['anger_frequency_SentiSense'] = l\n",
    "#df['anticipation_frequency_SentiSense'] = l\n",
    "#df['disgust_frequency_SentiSense'] = l\n",
    "#df['fear_frequency_SentiSense'] = l\n",
    "#df['joy_frequency_SentiSense'] = l\n",
    "#df['like_frequency_SentiSense'] = l\n",
    "#df['love_frequency_SentiSense'] = l\n",
    "#df['sadness_frequency_SentiSense'] = l\n",
    "df['surprise_frequency_SentiSense'] = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AFINN Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abandoned</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abandons</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abducted</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abduction</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abductions</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word  score\n",
       "0   abandoned     -2\n",
       "1    abandons     -2\n",
       "2    abducted     -2\n",
       "3   abduction     -2\n",
       "4  abductions     -2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "col = ['word','score']\n",
    "df_afinn = pd.read_excel(\"/Users/luciainesmerlo/Desktop/TFG/HaHackaton2020/lexicon/AFINN/afinnLexicon.xlsx\",names=col)\n",
    "df_afinn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon = {row['word'] : float(row['score']) for _, row in df_afinn.iterrows()} \n",
    "def Average(lst):\n",
    "    try:\n",
    "        return sum(lst) / len(lst)\n",
    "    except ZeroDivisionError:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = df['texto_limpio']\n",
    "afinn_lexicon_score = []\n",
    "\n",
    "for i, t in enumerate(texto):  \n",
    "    \n",
    "    lista = []\n",
    "    words = t.split()\n",
    "\n",
    "    for index, w in enumerate(words):\n",
    "        \n",
    "        val = lexicon.get(w)\n",
    "        if val:\n",
    "\n",
    "            lista.append(val)\n",
    "            \n",
    "    sentiment = Average(lista)\n",
    "    afinn_lexicon_score.append(sentiment)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['afinn_lexicon_score'] = afinn_lexicon_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIWC features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>PsicoLIWCachieve</th>\n",
       "      <th>PsicoLIWCadverb</th>\n",
       "      <th>PsicoLIWCaffect</th>\n",
       "      <th>PsicoLIWCanger</th>\n",
       "      <th>PsicoLIWCanx</th>\n",
       "      <th>PsicoLIWCarticle</th>\n",
       "      <th>PsicoLIWCassent</th>\n",
       "      <th>PsicoLIWCauxverb</th>\n",
       "      <th>PsicoLIWCbio</th>\n",
       "      <th>...</th>\n",
       "      <th>PsicoLIWCsocial</th>\n",
       "      <th>PsicoLIWCspace</th>\n",
       "      <th>PsicoLIWCswear</th>\n",
       "      <th>PsicoLIWCtentat</th>\n",
       "      <th>PsicoLIWCthey</th>\n",
       "      <th>PsicoLIWCtime</th>\n",
       "      <th>PsicoLIWCverb</th>\n",
       "      <th>PsicoLIWCwe</th>\n",
       "      <th>PsicoLIWCwork</th>\n",
       "      <th>PsicoLIWCyou</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  PsicoLIWCachieve  PsicoLIWCadverb  PsicoLIWCaffect  \\\n",
       "0           1                 1                1                2   \n",
       "1           2                 1                1                1   \n",
       "2           3                 0                1                0   \n",
       "\n",
       "   PsicoLIWCanger  PsicoLIWCanx  PsicoLIWCarticle  PsicoLIWCassent  \\\n",
       "0               1             0                 2                1   \n",
       "1               0             0                 4                0   \n",
       "2               0             0                 3                0   \n",
       "\n",
       "   PsicoLIWCauxverb  PsicoLIWCbio  ...  PsicoLIWCsocial  PsicoLIWCspace  \\\n",
       "0                 0             2  ...                1               3   \n",
       "1                 2             1  ...                7               2   \n",
       "2                 4             1  ...                2               2   \n",
       "\n",
       "   PsicoLIWCswear  PsicoLIWCtentat  PsicoLIWCthey  PsicoLIWCtime  \\\n",
       "0               1                0              0              0   \n",
       "1               0                0              0              2   \n",
       "2               0                0              0              1   \n",
       "\n",
       "   PsicoLIWCverb  PsicoLIWCwe  PsicoLIWCwork  PsicoLIWCyou  \n",
       "0              2            1              0             0  \n",
       "1              3            0              0             2  \n",
       "2              6            0              0             0  \n",
       "\n",
       "[3 rows x 65 columns]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_liwc = pd.read_excel(\"haha-2020-train-features-reynier.xlsx\",sheet_name='Hoja1')\n",
    "df_liwc.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_liwc=df_liwc.rename(columns={\"Unnamed: 0\":\"id\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>PsicoLIWCachieve</th>\n",
       "      <th>PsicoLIWCadverb</th>\n",
       "      <th>PsicoLIWCaffect</th>\n",
       "      <th>PsicoLIWCanger</th>\n",
       "      <th>PsicoLIWCanx</th>\n",
       "      <th>PsicoLIWCarticle</th>\n",
       "      <th>PsicoLIWCassent</th>\n",
       "      <th>PsicoLIWCauxverb</th>\n",
       "      <th>PsicoLIWCbio</th>\n",
       "      <th>...</th>\n",
       "      <th>PsicoLIWCsocial</th>\n",
       "      <th>PsicoLIWCspace</th>\n",
       "      <th>PsicoLIWCswear</th>\n",
       "      <th>PsicoLIWCtentat</th>\n",
       "      <th>PsicoLIWCthey</th>\n",
       "      <th>PsicoLIWCtime</th>\n",
       "      <th>PsicoLIWCverb</th>\n",
       "      <th>PsicoLIWCwe</th>\n",
       "      <th>PsicoLIWCwork</th>\n",
       "      <th>PsicoLIWCyou</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  PsicoLIWCachieve  PsicoLIWCadverb  PsicoLIWCaffect  PsicoLIWCanger  \\\n",
       "0   1                 1                1                2               1   \n",
       "1   2                 1                1                1               0   \n",
       "2   3                 0                1                0               0   \n",
       "\n",
       "   PsicoLIWCanx  PsicoLIWCarticle  PsicoLIWCassent  PsicoLIWCauxverb  \\\n",
       "0             0                 2                1                 0   \n",
       "1             0                 4                0                 2   \n",
       "2             0                 3                0                 4   \n",
       "\n",
       "   PsicoLIWCbio  ...  PsicoLIWCsocial  PsicoLIWCspace  PsicoLIWCswear  \\\n",
       "0             2  ...                1               3               1   \n",
       "1             1  ...                7               2               0   \n",
       "2             1  ...                2               2               0   \n",
       "\n",
       "   PsicoLIWCtentat  PsicoLIWCthey  PsicoLIWCtime  PsicoLIWCverb  PsicoLIWCwe  \\\n",
       "0                0              0              0              2            1   \n",
       "1                0              0              2              3            0   \n",
       "2                0              0              1              6            0   \n",
       "\n",
       "   PsicoLIWCwork  PsicoLIWCyou  \n",
       "0              0             0  \n",
       "1              0             2  \n",
       "2              0             0  \n",
       "\n",
       "[3 rows x 65 columns]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_liwc.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "      <th>Unnamed: 0.1.1.1</th>\n",
       "      <th>Unnamed: 0.1.1.1.1</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>is_humor</th>\n",
       "      <th>humor_rating</th>\n",
       "      <th>humor_controversy</th>\n",
       "      <th>...</th>\n",
       "      <th>PsicoLIWCsocial</th>\n",
       "      <th>PsicoLIWCspace</th>\n",
       "      <th>PsicoLIWCswear</th>\n",
       "      <th>PsicoLIWCtentat</th>\n",
       "      <th>PsicoLIWCthey</th>\n",
       "      <th>PsicoLIWCtime</th>\n",
       "      <th>PsicoLIWCverb</th>\n",
       "      <th>PsicoLIWCwe</th>\n",
       "      <th>PsicoLIWCwork</th>\n",
       "      <th>PsicoLIWCyou</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>TENNESSEE: We're the best state. Nobody even c...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>A man inserted an advertisement in the classif...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>How many men does it take to open a can of bee...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Told my mom I hit 1200 Twitter followers. She ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Roses are dead. Love is fake. Weddings are bas...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>7995</td>\n",
       "      <td>7995</td>\n",
       "      <td>7995</td>\n",
       "      <td>7995</td>\n",
       "      <td>7995</td>\n",
       "      <td>7996</td>\n",
       "      <td>Lack of awareness of the pervasiveness of raci...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>7996</td>\n",
       "      <td>7996</td>\n",
       "      <td>7996</td>\n",
       "      <td>7996</td>\n",
       "      <td>7996</td>\n",
       "      <td>7997</td>\n",
       "      <td>Why are aspirins white? Because they work sorry</td>\n",
       "      <td>1</td>\n",
       "      <td>1.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>7997</td>\n",
       "      <td>7997</td>\n",
       "      <td>7997</td>\n",
       "      <td>7997</td>\n",
       "      <td>7997</td>\n",
       "      <td>7998</td>\n",
       "      <td>Today, we Americans celebrate our independence...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>7998</td>\n",
       "      <td>7998</td>\n",
       "      <td>7998</td>\n",
       "      <td>7998</td>\n",
       "      <td>7998</td>\n",
       "      <td>7999</td>\n",
       "      <td>How to keep the flies off the bride at an Ital...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>7999</td>\n",
       "      <td>7999</td>\n",
       "      <td>7999</td>\n",
       "      <td>7999</td>\n",
       "      <td>7999</td>\n",
       "      <td>8000</td>\n",
       "      <td>\"Each ounce of sunflower seeds gives you 37% o...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  Unnamed: 0.1.1.1  \\\n",
       "0              0             0               0                 0   \n",
       "1              1             1               1                 1   \n",
       "2              2             2               2                 2   \n",
       "3              3             3               3                 3   \n",
       "4              4             4               4                 4   \n",
       "...          ...           ...             ...               ...   \n",
       "7995        7995          7995            7995              7995   \n",
       "7996        7996          7996            7996              7996   \n",
       "7997        7997          7997            7997              7997   \n",
       "7998        7998          7998            7998              7998   \n",
       "7999        7999          7999            7999              7999   \n",
       "\n",
       "      Unnamed: 0.1.1.1.1    id  \\\n",
       "0                      0     1   \n",
       "1                      1     2   \n",
       "2                      2     3   \n",
       "3                      3     4   \n",
       "4                      4     5   \n",
       "...                  ...   ...   \n",
       "7995                7995  7996   \n",
       "7996                7996  7997   \n",
       "7997                7997  7998   \n",
       "7998                7998  7999   \n",
       "7999                7999  8000   \n",
       "\n",
       "                                                   text  is_humor  \\\n",
       "0     TENNESSEE: We're the best state. Nobody even c...         1   \n",
       "1     A man inserted an advertisement in the classif...         1   \n",
       "2     How many men does it take to open a can of bee...         1   \n",
       "3     Told my mom I hit 1200 Twitter followers. She ...         1   \n",
       "4     Roses are dead. Love is fake. Weddings are bas...         1   \n",
       "...                                                 ...       ...   \n",
       "7995  Lack of awareness of the pervasiveness of raci...         0   \n",
       "7996    Why are aspirins white? Because they work sorry         1   \n",
       "7997  Today, we Americans celebrate our independence...         1   \n",
       "7998  How to keep the flies off the bride at an Ital...         1   \n",
       "7999  \"Each ounce of sunflower seeds gives you 37% o...         0   \n",
       "\n",
       "      humor_rating  humor_controversy  ...  PsicoLIWCsocial PsicoLIWCspace  \\\n",
       "0             2.42                1.0  ...                1              3   \n",
       "1             2.50                1.0  ...                7              2   \n",
       "2             1.95                0.0  ...                2              2   \n",
       "3             2.11                1.0  ...                5              2   \n",
       "4             2.78                0.0  ...                2              0   \n",
       "...            ...                ...  ...              ...            ...   \n",
       "7995           NaN                NaN  ...                5              1   \n",
       "7996          1.33                0.0  ...                1              0   \n",
       "7997          2.55                0.0  ...                4              0   \n",
       "7998          1.00                0.0  ...                2              2   \n",
       "7999           NaN                NaN  ...                3              1   \n",
       "\n",
       "      PsicoLIWCswear  PsicoLIWCtentat  PsicoLIWCthey PsicoLIWCtime  \\\n",
       "0                  1                0              0             0   \n",
       "1                  0                0              0             2   \n",
       "2                  0                0              0             1   \n",
       "3                  0                0              0             0   \n",
       "4                  0                0              0             0   \n",
       "...              ...              ...            ...           ...   \n",
       "7995               0                3              0             0   \n",
       "7996               0                0              1             0   \n",
       "7997               0                0              0             2   \n",
       "7998               1                0              0             1   \n",
       "7999               0                0              0             1   \n",
       "\n",
       "     PsicoLIWCverb PsicoLIWCwe  PsicoLIWCwork PsicoLIWCyou  \n",
       "0                2           1              0            0  \n",
       "1                3           0              0            2  \n",
       "2                6           0              0            0  \n",
       "3                3           0              0            0  \n",
       "4                4           0              0            0  \n",
       "...            ...         ...            ...          ...  \n",
       "7995             3           3              0            0  \n",
       "7996             1           0              1            0  \n",
       "7997             0           3              0            0  \n",
       "7998             2           0              0            0  \n",
       "7999             2           0              0            2  \n",
       "\n",
       "[8000 rows x 129 columns]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.merge(df, df_liwc, on=\"id\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tipology of groups and social categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\tnational groups\n",
    "2\tIlness/heath groups\n",
    "3\tAge groups\n",
    "4\tVictims\n",
    "5\tPolitical group\n",
    "6\tEthinc \n",
    "7\tInmigration\n",
    "8\tProfessional and class groups\n",
    "9\tSexual Categories\n",
    "10\tWomen\n",
    "11\tPhysical appearance\n",
    "12\tReligion\n",
    "13\tStyle of life\n",
    "14\tNon normative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "      <th>Unnamed: 0.1.1.1</th>\n",
       "      <th>Unnamed: 0.1.1.1.1</th>\n",
       "      <th>Unnamed: 0.1.1.1.1.1</th>\n",
       "      <th>Unnamed: 0.1.1.1.1.1.1</th>\n",
       "      <th>Unnamed: 0.1.1.1.1.1.1.1</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>...</th>\n",
       "      <th>PsicoLIWCwe</th>\n",
       "      <th>PsicoLIWCwork</th>\n",
       "      <th>PsicoLIWCyou</th>\n",
       "      <th>first_person_singular_pronoun</th>\n",
       "      <th>second_person_singular_pronoun</th>\n",
       "      <th>third_person_singular_pronoun</th>\n",
       "      <th>first_person_plural_pronoun</th>\n",
       "      <th>second_person_plural_pronoun</th>\n",
       "      <th>third_person_plural_pronoun</th>\n",
       "      <th>punctuation_symbols</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>TENNESSEE: We're the best state. Nobody even c...</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>A man inserted an advertisement in the classif...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 125 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  Unnamed: 0.1.1.1  \\\n",
       "0           0             0               0                 0   \n",
       "1           1             1               1                 1   \n",
       "\n",
       "   Unnamed: 0.1.1.1.1  Unnamed: 0.1.1.1.1.1  Unnamed: 0.1.1.1.1.1.1  \\\n",
       "0                   0                     0                       0   \n",
       "1                   1                     1                       1   \n",
       "\n",
       "   Unnamed: 0.1.1.1.1.1.1.1  id  \\\n",
       "0                         0   1   \n",
       "1                         1   2   \n",
       "\n",
       "                                                text  ...  PsicoLIWCwe  \\\n",
       "0  TENNESSEE: We're the best state. Nobody even c...  ...            1   \n",
       "1  A man inserted an advertisement in the classif...  ...            0   \n",
       "\n",
       "   PsicoLIWCwork  PsicoLIWCyou  first_person_singular_pronoun  \\\n",
       "0              0             0                              0   \n",
       "1              0             2                              1   \n",
       "\n",
       "  second_person_singular_pronoun  third_person_singular_pronoun  \\\n",
       "0                              0                              0   \n",
       "1                              0                              0   \n",
       "\n",
       "   first_person_plural_pronoun  second_person_plural_pronoun  \\\n",
       "0                            1                             0   \n",
       "1                            0                             0   \n",
       "\n",
       "  third_person_plural_pronoun punctuation_symbols  \n",
       "0                           0                   4  \n",
       "1                           0                   4  \n",
       "\n",
       "[2 rows x 125 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df = pd.read_excel(\"datos_features.xlsx\")\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.0</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.0</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.0</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cat  size\n",
       "0    1.0   153\n",
       "1    2.0    53\n",
       "2    3.0    27\n",
       "3    4.0   110\n",
       "4    5.0    30\n",
       "5    6.0    64\n",
       "6    7.0    10\n",
       "7    8.0    17\n",
       "8    9.0    41\n",
       "9   10.0    21\n",
       "10  11.0    15\n",
       "11  12.0    34\n",
       "12  13.0    34\n",
       "13  14.0    22"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "social = pd.read_excel('TIPOLOGY OF GROUPS AND SOCIAL CATEGORIES.xlsx',sheet_name='Hoja1')\n",
    "social.groupby(['cat'],as_index=False).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon = {row['word'] : str(row['cat']) for _, row in social.iterrows()} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat(num):\n",
    "    if num == '1.0':\n",
    "        return 'national groups'\n",
    "    elif num == '2.0':\n",
    "        return 'Ilness/heath groups'\n",
    "    elif num == '3.0':\n",
    "        return 'Age groups'\n",
    "    elif num == '4.0':\n",
    "        return 'Victims'\n",
    "    elif num == '5.0':\n",
    "        return 'Political group'\n",
    "    elif num == '6.0':\n",
    "        return 'Ethinc'\n",
    "    elif num == '7.0':\n",
    "        return 'Inmigration'\n",
    "    elif num == '8.0':\n",
    "        return 'Professional and class groups'\n",
    "    elif num == '9.0':\n",
    "        return 'Sexual Categories'\n",
    "    elif num == '10.0':\n",
    "        return 'Women'\n",
    "    elif num == '11.0':\n",
    "        return 'Physical appearance'\n",
    "    elif num == '12.0':\n",
    "        return 'Religion'\n",
    "    elif num == '13.0':\n",
    "        return 'Style of life'\n",
    "    elif num == '14.0':\n",
    "        return 'Non normative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = df['texto_limpio']\n",
    "\n",
    "def generate_N_grams(text,ngram=1):\n",
    "    \n",
    "    words=[word for word in text.split(\" \") ]  \n",
    "          \n",
    "    temp=zip(*[words[i:] for i in range(0,ngram)])\n",
    "    ans={' '.join(ngram):1 for ngram in temp}\n",
    "    return ans\n",
    "\n",
    "l_national_groups = []\n",
    "l_Ilness_heath_groups= []\n",
    "l_Age_groups= []\n",
    "l_Victims= []\n",
    "l_Political_group= []\n",
    "l_Ethinc= []\n",
    "l_Inmigration= []\n",
    "l_Professional_and_class_groups= []\n",
    "l_Sexual_Categories= []\n",
    "l_Women= []\n",
    "l_Physical_appearance= []\n",
    "l_Religion= []\n",
    "l_Style_of_life= []\n",
    "l_Non_normative= []\n",
    "\n",
    "sc = set()\n",
    "\n",
    "for i in text: \n",
    "    \n",
    "    unigrama = generate_N_grams(i,1)\n",
    "    bigrama = generate_N_grams(i,2)\n",
    "    trigrama = generate_N_grams(i,3)\n",
    "    cuatrigrama = generate_N_grams(i,4)\n",
    "    cincograma = generate_N_grams(i,5)\n",
    "    seisgrama = generate_N_grams(i,6)\n",
    "    sietegrama = generate_N_grams(i,7)\n",
    "    ochograma = generate_N_grams(i,8)\n",
    "    gramas = {**unigrama, **bigrama,**trigrama,**cuatrigrama,**cincograma,**ochograma,**seisgrama,**sietegrama}\n",
    "    \n",
    "    s1 = 0\n",
    "    s2 = 0\n",
    "    s3 = 0\n",
    "    s4 = 0\n",
    "    s5 = 0\n",
    "    s6 = 0\n",
    "    s7 = 0\n",
    "    s8 = 0\n",
    "    s9 = 0\n",
    "    s10 = 0\n",
    "    s11= 0\n",
    "    s12 = 0\n",
    "    s13 = 0\n",
    "    s14 = 0\n",
    "    \n",
    "    for key in gramas:\n",
    "        word_category = lexicon.get(key)\n",
    "        \n",
    "        \n",
    "        if word_category == '1.0': s1 += 1\n",
    "        elif word_category == '2.0': s2 += 1\n",
    "        elif word_category == '3.0': s3 += 1\n",
    "        elif word_category == '4.0': s4 += 1\n",
    "        elif word_category == '5.0': s5 += 1\n",
    "        elif word_category == '6.0': s6 += 1\n",
    "        elif word_category == '7.0': s7 += 1\n",
    "        elif word_category == '8.0': s8 += 1\n",
    "        elif word_category == '9.0': \n",
    "            s9 += 1\n",
    "            sc.add(key)\n",
    "        elif word_category == '10.0': s10 += 1\n",
    "        elif word_category == '11.0': s11 += 1\n",
    "        elif word_category == '12.0': s12 += 1\n",
    "        elif word_category == '13.0': s13 += 1\n",
    "        elif word_category == '14.0': s14 += 1\n",
    "          \n",
    "    l_national_groups.append(s1)\n",
    "    l_Ilness_heath_groups.append(s2)\n",
    "    l_Age_groups.append(s3)\n",
    "    l_Victims.append(s4)\n",
    "    l_Political_group.append(s5)\n",
    "    l_Ethinc.append(s6)\n",
    "    l_Inmigration.append(s7)\n",
    "    l_Professional_and_class_groups.append(s8)\n",
    "    l_Sexual_Categories.append(s9)\n",
    "    l_Women.append(s10)\n",
    "    l_Physical_appearance.append(s11)\n",
    "    l_Religion.append(s12)\n",
    "    l_Style_of_life.append(s13)\n",
    "    l_Non_normative.append(s14)    \n",
    "            \n",
    "    \n",
    "len(l_national_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gay people', 'lgbt community', 'cis', 'lgbt', 'trans folk', 'gay', 'trans people'] ['snatch', 'tomato', 'dome', 'faggot', 'bean', 'slit', 'puss', 'turnip', 'squash', 'melon', 'homo', 'cunt', 'pumpkin', 'potato', 'attic', 'bittersweet', 'gay', 'stupid', 'cucumber', 'fag', 'queer', 'noodle']\n"
     ]
    }
   ],
   "source": [
    "print(list(sc),list(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['national_groups']=l_national_groups\n",
    "\n",
    "df['Ilness/heath_groups']=l_Ilness_heath_groups\n",
    "\n",
    "df['Age_groups']=l_Age_groups\n",
    "\n",
    "df['Victims']=l_Victims\n",
    "\n",
    "df['Political_group']=l_Political_group\n",
    "\n",
    "df['Ethinc']=l_Ethinc\n",
    "\n",
    "df['Inmigration']=l_Inmigration\n",
    "\n",
    "df['Professional_and_class_groups']=l_Professional_and_class_groups\n",
    "\n",
    "df['Sexual_Categories']=l_Sexual_Categories\n",
    "\n",
    "df['Women']=l_Women\n",
    "\n",
    "df['Physical_appearance']=l_Physical_appearance\n",
    "\n",
    "df['Religion']=l_Religion\n",
    "\n",
    "df['Style_of_life']=l_Style_of_life\n",
    "\n",
    "df['Non_normative']=l_Non_normative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "df.to_excel('/Users/luciainesmerlo/Desktop/TFG/HaHackaton2020/datos_features.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
