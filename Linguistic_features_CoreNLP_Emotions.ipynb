{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/clemtoy/WNAffect\n",
    "#https://wordnet.princeton.edu/documentation\n",
    "#https://wordnet.princeton.edu/download/current-version\n",
    "#https://medium.com/geekculture/simple-emotion-classification-in-python-40fb24692541"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentic import SenticPhrase\n",
    "import sentic\n",
    "import senticnet\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "import string\n",
    "import spacy\n",
    "import stanza\n",
    "import nltk\n",
    "import ssl\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nrclex import NRCLex\n",
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "from afinn import Afinn\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\"datos_train.csv\",sep = ',')\n",
    "import pandas as pd\n",
    "df = pd.read_excel(\"datos_features.xlsx\")\n",
    "#df.emotions_NRCLex_categories.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Emotions with NRCLex\n",
    "Con NRCLex, se usa un lexicon de 10000 a 27000 palabras, basadas en sinónimos de WordNet.\n",
    "Para cada fila, devuelve las emociones con score más elevado.\n",
    "\n",
    "https://pypi.org/project/NRCLex/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "      <th>Unnamed: 0.1.1.1</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>is_humor</th>\n",
       "      <th>humor_rating</th>\n",
       "      <th>humor_controversy</th>\n",
       "      <th>offense_rating</th>\n",
       "      <th>texto_limpio</th>\n",
       "      <th>sentimiento_stanza</th>\n",
       "      <th>polaridad_media_sentic</th>\n",
       "      <th>sentiwordnet_score</th>\n",
       "      <th>sentiwordnet_overall_Sentiment</th>\n",
       "      <th>emotions_NRCLex</th>\n",
       "      <th>emotions_NRCLex_categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>TENNESSEE: We're the best state. Nobody even c...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>tennessee we be the good state nobody even com...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.089556</td>\n",
       "      <td>0.625</td>\n",
       "      <td>Positive</td>\n",
       "      <td>[(anger, 0.125), (trust, 0.125), (surprise, 0....</td>\n",
       "      <td>[anger, trust, surprise, positive, negative, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>A man inserted an advertisement in the classif...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>a man insert a advertisement in the classified...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.166355</td>\n",
       "      <td>0.750</td>\n",
       "      <td>Positive</td>\n",
       "      <td>[(positive, 0.6666666666666666)]</td>\n",
       "      <td>[positive]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>How many men does it take to open a can of bee...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>how many man do it take to open a can of beer ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.088885</td>\n",
       "      <td>-0.375</td>\n",
       "      <td>Negative</td>\n",
       "      <td>[(positive, 0.25), (sadness, 0.25), (joy, 0.25...</td>\n",
       "      <td>[positive, sadness, joy, anticipation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Told my mom I hit 1200 Twitter followers. She ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tell my mom i hit twitter follower she point o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.032154</td>\n",
       "      <td>1.000</td>\n",
       "      <td>Positive</td>\n",
       "      <td>[(trust, 0.4)]</td>\n",
       "      <td>[trust]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Roses are dead. Love is fake. Weddings are bas...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>rose be dead love be fake wedding be basically...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.059833</td>\n",
       "      <td>-0.375</td>\n",
       "      <td>Negative</td>\n",
       "      <td>[(positive, 0.25), (negative, 0.25), (sadness,...</td>\n",
       "      <td>[positive, negative, sadness, joy]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  Unnamed: 0.1.1.1  id  \\\n",
       "0           0             0               0                 0   1   \n",
       "1           1             1               1                 1   2   \n",
       "2           2             2               2                 2   3   \n",
       "3           3             3               3                 3   4   \n",
       "4           4             4               4                 4   5   \n",
       "\n",
       "                                                text  is_humor  humor_rating  \\\n",
       "0  TENNESSEE: We're the best state. Nobody even c...         1          2.42   \n",
       "1  A man inserted an advertisement in the classif...         1          2.50   \n",
       "2  How many men does it take to open a can of bee...         1          1.95   \n",
       "3  Told my mom I hit 1200 Twitter followers. She ...         1          2.11   \n",
       "4  Roses are dead. Love is fake. Weddings are bas...         1          2.78   \n",
       "\n",
       "   humor_controversy  offense_rating  \\\n",
       "0                1.0             0.2   \n",
       "1                1.0             1.1   \n",
       "2                0.0             2.4   \n",
       "3                1.0             0.0   \n",
       "4                0.0             0.1   \n",
       "\n",
       "                                        texto_limpio  sentimiento_stanza  \\\n",
       "0  tennessee we be the good state nobody even com...                   0   \n",
       "1  a man insert a advertisement in the classified...                   1   \n",
       "2  how many man do it take to open a can of beer ...                   0   \n",
       "3  tell my mom i hit twitter follower she point o...                   1   \n",
       "4  rose be dead love be fake wedding be basically...                   1   \n",
       "\n",
       "   polaridad_media_sentic  sentiwordnet_score sentiwordnet_overall_Sentiment  \\\n",
       "0                0.089556               0.625                       Positive   \n",
       "1                0.166355               0.750                       Positive   \n",
       "2                0.088885              -0.375                       Negative   \n",
       "3                0.032154               1.000                       Positive   \n",
       "4                0.059833              -0.375                       Negative   \n",
       "\n",
       "                                     emotions_NRCLex  \\\n",
       "0  [(anger, 0.125), (trust, 0.125), (surprise, 0....   \n",
       "1                   [(positive, 0.6666666666666666)]   \n",
       "2  [(positive, 0.25), (sadness, 0.25), (joy, 0.25...   \n",
       "3                                     [(trust, 0.4)]   \n",
       "4  [(positive, 0.25), (negative, 0.25), (sadness,...   \n",
       "\n",
       "                          emotions_NRCLex_categories  \n",
       "0  [anger, trust, surprise, positive, negative, d...  \n",
       "1                                         [positive]  \n",
       "2             [positive, sadness, joy, anticipation]  \n",
       "3                                            [trust]  \n",
       "4                 [positive, negative, sadness, joy]  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def emotions_nrclex(texto):\n",
    "    \n",
    "    for i in range(len(texto)):\n",
    "        text_object = NRCLex(texto[i])\n",
    "        emotions = text_object.top_emotions # text_object.affect_frequencies \n",
    "                                        #diccionario con todas las emociones y sus fr.rel\n",
    "        yield emotions\n",
    "\n",
    "emotions_NRCLex = []\n",
    "emotions_NRCLex_categories = []\n",
    "\n",
    "for i in emotions_nrclex(df['texto_limpio']):\n",
    "    emotions_NRCLex.append(i)\n",
    "    emotions_NRCLex_category = [tag for tag,freq in i]\n",
    "    emotions_NRCLex_categories.append(emotions_NRCLex_category)\n",
    "\n",
    "df['emotions_NRCLex'] = emotions_NRCLex\n",
    "#df['emotions_NRCLex_categories'] = emotions_NRCLex_categories\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Afinn score  doc:http://www2.imm.dtu.dk/pubdb/edoc/imm6006.pdf\n",
    "\n",
    "AFINN lexicon asigna a palabras un score entre -5 a 5. Los scores negativos indican sentimientos negativos, y scores positivos indican sentimientos positivos.\n",
    "Valor de cada token en la oración se suma, por lo que el valor de esos sentimientos son arbitrarios.\n",
    "https://github.com/thisandagain/sentiment/issues/137#issuecomment-398951315\n",
    "Variación de ANEW lexicon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "afinn = Afinn(language='en')\n",
    "df['afinn_score'] = df['texto_limpio'].apply(afinn.score)\n",
    "\n",
    "def tag(scores):\n",
    "    sentiment = ['positive' if score > 0 \n",
    "                          else 'negative' if score < 0 \n",
    "                              else 'neutral' \n",
    "                                  for score in scores]\n",
    "    return sentiment\n",
    "tag = tag(df['afinn_score'])\n",
    "df['afinn_score_tag'] = tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   -1\n",
       "1    2\n",
       "2    0\n",
       "3    1\n",
       "4   -3\n",
       "Name: afinn_score, dtype: int64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel(\"datos_features.xlsx\")\n",
    "df['afinn_score'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['afinn_score'].unique()\n",
    "from afinn import Afinn\n",
    "afinn = Afinn(language='en')\n",
    "l=['crisis','no']\n",
    "afinn.score('no')+afinn.score('no')+afinn.score('no')+afinn.score('no')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ANEW Score\n",
    "database of 14.000 English words that have been manually rated by many human volunteers on three affective measures: pleasure (valence), arousal (excitement), and dominance (level of control),split data by gender, age, and educational differences in raters.\n",
    "affective ratings are on a scale from 1 to 9, where 1 is the least pleasurable/exciting/controlling, and 9 is the most.\n",
    "\n",
    "Analisis palabra a palabra. si una palabra tiene en sus tres palabras o menos, anteriores una negativa, se invierte el valor de polaridad.\n",
    "se extrae el valor de cada palabra de cada tipo de característica , y se hace la media para las 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/dwzhou/SentimentAnalysis\n",
    "#df_anew = pd.read_csv('https://raw.githubusercontent.com/dwzhou/SentimentAnalysis/master/lib/EnglishShortened.csv')\n",
    "#df_anew.to_csv('/Users/luciainesmerlo/Desktop/TFG/HaHackaton2020/datos_anew.csv', sep=',')\n",
    "df_anew = pd.read_csv('datos_anew.csv',sep=',')\n",
    "#df_anew.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_negative_words(words):\n",
    "    #return any(word in ('not', 'n', \"n't\",'no') for word in words)\n",
    "    return any(word in (\"no\", \"without\", \"nil\",\"not\", \"n't\", \"never\", \"none\", \"neith\", \"nor\", \"non\",\n",
    "                       \"deny\", \"reject\", \"refuse\", \"subside\", \"retract\", \"non\")\n",
    "               for word in words)\n",
    "\n",
    "def Average(lst):\n",
    "    try:\n",
    "        return sum(lst) / len(lst)\n",
    "    except ZeroDivisionError:\n",
    "        return 0\n",
    "\n",
    "texto = df['texto_limpio']\n",
    "anew_score_sentiment = []\n",
    "anew_score_arousal = []\n",
    "anew_score_dominance = []\n",
    "\n",
    "words_sentiment = {\n",
    "    row['Word']: {\n",
    "        'valence': float(row['valence']),\n",
    "        'arousal': float(row['arousal']),\n",
    "        'dominance': float(row['dominance']),\n",
    "    }\n",
    "    \n",
    "    for _, row in df_anew.iterrows()\n",
    "}\n",
    "\n",
    "for i, t in enumerate(texto):  \n",
    "\n",
    "    # print('oracion',i)\n",
    "    v_list = []  # holds valence scores\n",
    "    a_list = []  # holds arousal scores\n",
    "    d_list = []  # holds dominance scores\n",
    "    found_words = 0\n",
    "    words = t.split()\n",
    "\n",
    "    for index, w in enumerate(words):\n",
    "\n",
    "        # check for negation in 3 words before current word\n",
    "        neg = detect_negative_words(words[max(index-3, 0):index])\n",
    "\n",
    "        word_sentiment = words_sentiment.get(w)\n",
    "        if word_sentiment:\n",
    "            found_words += 1\n",
    "            v = word_sentiment['valence']  # valence (pleasure)\n",
    "            a = word_sentiment['arousal']  # arousal (excitement)\n",
    "            d = word_sentiment['dominance']  # dominance (level of control)\n",
    "\n",
    "            if neg:  # reverse polarity for this word\n",
    "                v = 5 - (v - 5)\n",
    "                a = 5 - (a - 5)\n",
    "                d = 5 - (d - 5)\n",
    "            v_list.append(v)\n",
    "            a_list.append(a)\n",
    "            d_list.append(d)\n",
    " \n",
    "    sentiment = Average(v_list)\n",
    "    arousal = Average(a_list)\n",
    "    dominance = Average(d_list)\n",
    "\n",
    "    anew_score_sentiment.append(sentiment)\n",
    "    anew_score_arousal.append(arousal)\n",
    "    anew_score_dominance.append(dominance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment_anew']=anew_score_sentiment\n",
    "df['arousal_anew']=anew_score_arousal\n",
    "df['dominance_anew']=anew_score_dominance\n",
    "label_anew = []\n",
    "\n",
    "for i,value in enumerate(df['sentiment_anew']):\n",
    "    \n",
    "    if value > 6:\n",
    "        label = 'positive'\n",
    "    elif value < 4:\n",
    "        label = 'negative'\n",
    "    else:\n",
    "        label = 'neutral'\n",
    "        \n",
    "    label_anew.append(label)\n",
    "    \n",
    "df['label_anew']=label_anew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Scores lexicon-abusive-words binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_binary = pd.read_csv('https://raw.githubusercontent.com/uds-lsv/lexicon-of-abusive-words/master/Lexicons/baseLexicon.txt')\n",
    "#df_binary.to_csv('/Users/luciainesmerlo/Desktop/TFG/HaHackaton2020/lexicon-of-abusive-words-binary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_binary = pd.read_excel('/Users/luciainesmerlo/Desktop/TFG/HaHackaton2020/binary-lexicon-abusive-words.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tags(tag):\n",
    "    if tag.startswith('adj'):\n",
    "        return 'ADJ'\n",
    "    elif tag.startswith('noun'):\n",
    "        return 'NOUN'\n",
    "    elif tag.startswith('verb'):\n",
    "        return 'VERB'\n",
    "    else:\n",
    "        return None\n",
    "# https://universaldependencies.org/u/pos/index.html\n",
    "\n",
    "words_abusive = {\n",
    "    row['word']: {\n",
    "        'tag': tags(str(row['tag'])),\n",
    "        'class': str(row['class'])\n",
    "    }\n",
    "    \n",
    "    for _, row in df_binary.iterrows()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=df['texto_limpio']\n",
    "\n",
    "def tageo(rows):\n",
    "    nlp = stanza.Pipeline(lang='en', processors='tokenize,mwt,pos')\n",
    "    for i, t in enumerate(rows):\n",
    "        \n",
    "        scores = []\n",
    "        pos_tag = nlp(t)\n",
    "        pos_tagging = {\n",
    "            word.text : word.upos\n",
    "            for sent in pos_tag.sentences for word in sent.words\n",
    "        }\n",
    "        \n",
    "        yield pos_tagging\n",
    "        \n",
    "tagged_words = tageo(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-17 17:57:38 WARNING: Can not find mwt: default from official model list. Ignoring it.\n",
      "2022-03-17 17:57:38 INFO: Loading these models for language: en (English):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | combined |\n",
      "| pos       | combined |\n",
      "========================\n",
      "\n",
      "2022-03-17 17:57:38 INFO: Use device: cpu\n",
      "2022-03-17 17:57:38 INFO: Loading: tokenize\n",
      "2022-03-17 17:57:38 INFO: Loading: pos\n",
      "2022-03-17 17:57:38 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for index, p in enumerate(tagged_words):\n",
    "    # p es un diccionario\n",
    "    for k, v in p.items():\n",
    "        score = 0\n",
    "        info_word = words_abusive.get(k)\n",
    "        \n",
    "        if info_word:\n",
    "            tag_in_lexicon = info_word.get('tag') \n",
    "            class_in_lexicon = info_word.get('class')\n",
    "            \n",
    "            if tag_in_lexicon == tag_in_lexicon and class_in_lexicon == 'True':\n",
    "                score += 1\n",
    "                \n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['abusive_scores_binary']=scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Scores lexicon-abusive-words expanded\n",
    "\n",
    "dado este lexicon, que contiene palabras, su tipo y su score, se computa para cada palabra en las lineas su score (se considera si esa palabra con el mismo tipo está en ambos datasets) para posteriormente calcular el valor medio de la oración. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_abusive = pd.read_csv('https://raw.githubusercontent.com/uds-lsv/lexicon-of-abusive-words/master/Lexicons/expandedLexicon.txt')\n",
    "#df_abusive.to_csv('/Users/luciainesmerlo/Desktop/TFG/HaHackaton2020/lexicon-of-abusive-words.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_abusive = pd.read_excel('/Users/luciainesmerlo/Desktop/TFG/HaHackaton2020/lexicon-abusive-words.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Average(lst):\n",
    "    try:\n",
    "        return sum(lst) / len(lst)\n",
    "    except ZeroDivisionError:\n",
    "        return 0\n",
    "\n",
    "def tags(tag):\n",
    "    if tag.startswith('adj'):\n",
    "        return 'ADJ'\n",
    "    elif tag.startswith('noun'):\n",
    "        return 'NOUN'\n",
    "    elif tag.startswith('verb'):\n",
    "        return 'VERB'\n",
    "    else:\n",
    "        return None\n",
    "# https://universaldependencies.org/u/pos/index.html\n",
    "\n",
    "words_abusive = {\n",
    "    row['word']: {\n",
    "        'tag': tags(row['tag']),\n",
    "        'score': float(row['score'])\n",
    "    }\n",
    "    \n",
    "    for _, row in df_abusive.iterrows()\n",
    "}\n",
    "\n",
    "text=df['texto_limpio']\n",
    "\n",
    "def tageo(rows):\n",
    "    nlp = stanza.Pipeline(lang='en', processors='tokenize,mwt,pos')\n",
    "    for i, t in enumerate(rows):\n",
    "        scores = []\n",
    "        pos_tag = nlp(t)\n",
    "        pos_tagging = [(word.text,word.upos) for sent in pos_tag.sentences \n",
    "                       for word in sent.words]\n",
    "        yield pos_tagging\n",
    "        \n",
    "tagged_words = tageo(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-11 13:16:39 WARNING: Can not find mwt: default from official model list. Ignoring it.\n",
      "2022-03-11 13:16:39 INFO: Loading these models for language: en (English):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | combined |\n",
      "| pos       | combined |\n",
      "========================\n",
      "\n",
      "2022-03-11 13:16:39 INFO: Use device: cpu\n",
      "2022-03-11 13:16:39 INFO: Loading: tokenize\n",
      "2022-03-11 13:16:39 INFO: Loading: pos\n",
      "2022-03-11 13:16:39 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "abusive_scores = []\n",
    "\n",
    "for index, p in enumerate(tagged_words): #for each line\n",
    "    scores = []\n",
    "    for i, text in enumerate(p):\n",
    "        \n",
    "        word = text[0]\n",
    "        tag_of_word = text[1]\n",
    "\n",
    "        info_word = words_abusive.get(word)\n",
    "        \n",
    "        if info_word:\n",
    "            \n",
    "            tag_in_lexicon = info_word.get('tag')\n",
    "            \n",
    "            if tag_of_word == tag_in_lexicon:\n",
    "                score = info_word.get('score')\n",
    "            else:\n",
    "                score = 0\n",
    "            \n",
    "            scores.append(score)\n",
    "                \n",
    "    s = Average(scores)\n",
    "    abusive_scores.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['abusive_scores']=abusive_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "df.to_excel('/Users/luciainesmerlo/Desktop/TFG/HaHackaton2020/datos_features.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
